{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "TypeA_Atrium_MRI_Unet_Pytorch_Training_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/146790g/TCGA-Breast-Cancer-Biomarker/blob/master/TypeA_Atrium_MRI_Unet_Pytorch_Training_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Data Set** : Atrium MRI\n",
        "\n",
        "> **Model**: Unet\n",
        "\n",
        "> **Coding** **Stye**: TypeA\n",
        "\n",
        "> **Section**: Training\n",
        "\n",
        "> **SubSection**: continued training , 02"
      ],
      "metadata": {
        "id": "FKjKBLLYAvla"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aPK7bsjlwQN",
        "outputId": "5adaed64-b64d-45e7-91d2-3091ec72763a"
      },
      "source": [
        "%pwd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvcb-3pQlylP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff532a39-124d-4c1e-b93e-ab2dbe332d7a"
      },
      "source": [
        "!pip install imgaug==0.4.0\n",
        "!pip install nibabel==3.2.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.8.1.post1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (0.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.4.0) (4.1.1)\n",
            "Requirement already satisfied: nibabel==3.2.1 in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from nibabel==3.2.1) (21.3)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from nibabel==3.2.1) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->nibabel==3.2.1) (3.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ランタイムを再実行ボタンを押す"
      ],
      "metadata": {
        "id": "ONj5Q7lYBsZY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zCxnWoIlr5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067a4b3d-4062-455f-918f-d3418285c098"
      },
      "source": [
        "# パッケージのimport\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import PIL\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import keras\n",
        "print(keras.__version__)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "import imgaug\n",
        "import imageio\n",
        "import numpy as np\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "\n",
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "# パッケージのimport\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "#import torch.utils.data as data\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import PIL\n",
        "import cv2\n",
        "\n",
        "# パッケージのimport\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "# パッケージのimport\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "#import torch.utils.data as data\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxiKfixThGiZ",
        "outputId": "71a7e146-6542-4976-87e3-78770e4fcaee"
      },
      "source": [
        "print(cv2.__version__)\n",
        "print(PIL.__version__)\n",
        "print(torch.__version__)\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1.2\n",
            "7.1.2\n",
            "1.10.0+cu111\n",
            "2.8.0\n",
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUが使えるかを確認\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDk9_PeQ54HX",
        "outputId": "e2e9c131-daa6-4095-e2a2-86c03e67a795"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス： cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = Path('/content/gdrive/My Drive/Colab Notebooks/BBB Pytorch Lightning Udemy/06 Atrium Segmentation')\n",
        "data_dir = root_dir/Path('Preprocessed')\n",
        "metrics_dir = root_dir/Path('metrics')\n",
        "network_dir = root_dir/Path('network')\n",
        "\n",
        "import os\n",
        "os.chdir(root_dir)\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaNV8PG84j7q",
        "outputId": "bd79c29c-0747-4718-d009-124f4a663dfb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/BBB Pytorch Lightning Udemy/06 Atrium Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataloaderからバッチデータを作成"
      ],
      "metadata": {
        "id": "pU6-toW7Dg6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from dsets.dsets import ImageTransform\n",
        "import random\n",
        "from dsets.dsets import MakeDataset\n",
        "from dsets.dsets import make_path_list\n",
        "from dsets.dsets import MakeDataset_wo_ImageTransform\n",
        "import torch.utils.data as data\n",
        "\n",
        "train_list = make_path_list(data_dir,phase=\"train\")\n",
        "val_list = make_path_list(data_dir,phase=\"val\")\n",
        "\n",
        "file_list={'train':train_list,'val':val_list}\n",
        "\n",
        "train_dataset = MakeDataset(file_list=file_list,transform=ImageTransform,phase='train')\n",
        "val_dataset = MakeDataset(file_list=file_list,phase='val')\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "train_dl = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dl = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}\n"
      ],
      "metadata": {
        "id": "KG3x_H2w4lPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44eff6e-0a40-41b8-898c-e3786e490c99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/imgaug/imgaug.py:184: DeprecationWarning: Function `SegmentationMapOnImage()` is deprecated. Use `SegmentationMapsOnImage` instead. (Note the plural 'Maps' instead of old 'Map'.).\n",
            "  warn_deprecated(msg, stacklevel=3)\n",
            "/usr/local/lib/python3.7/dist-packages/imgaug/imgaug.py:106: DeprecationWarning: Providing nb_classes to SegmentationMapsOnImage is no longer necessary and hence deprecated. The argument is ignored and can be safely removed.\n",
            "  warn(msg, category=DeprecationWarning, stacklevel=stacklevel)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataloaders_dict['train'].dataset))\n",
        "print(len(dataloaders_dict['train']))\n",
        "2271%4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk_8kWk8w4Ga",
        "outputId": "33415664-dcad-4535-b771-7de3ff6781c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2271\n",
            "228\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataloaders_dict['val'].dataset))\n",
        "print(len(dataloaders_dict['val']))"
      ],
      "metadata": {
        "id": "W_-OBzGIwXjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2c1c20-df14-4028-a714-e03444adee14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2271\n",
            "228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnG-BM8jlr5j"
      },
      "source": [
        "#Unet作成"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch.nn import init\n",
        "import functools\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "class DoubleConv(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Helper Class which implements the intermediate Convolutions\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.step = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                                        torch.nn.ReLU(),\n",
        "                                        torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                                        torch.nn.ReLU())\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.step(X)\n",
        "\n",
        "\n",
        "class UNet(torch.nn.Module):\n",
        "    def __init__(self,n_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layer1 = DoubleConv(1, 64)\n",
        "        self.layer2 = DoubleConv(64, 128)\n",
        "        self.layer3 = DoubleConv(128, 256)\n",
        "        self.layer4 = DoubleConv(256, 512)\n",
        "        \n",
        "        self.layer5 = DoubleConv(512+256, 256)\n",
        "        self.layer6 = DoubleConv(256+128, 128)\n",
        "        self.layer7 = DoubleConv(128+64, 64)\n",
        "        self.layer8 = torch.nn.Conv2d(64,n_classes,1)\n",
        "        \n",
        "        self.maxpool = torch.nn.MaxPool2d(2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x1 = self.layer1(x)\n",
        "        x1m = self.maxpool(x1)\n",
        "        \n",
        "        x2 = self.layer2(x1m)\n",
        "        x2m = self.maxpool(x2)\n",
        "        \n",
        "        x3 = self.layer3(x2m)\n",
        "        x3m = self.maxpool(x3)\n",
        "        \n",
        "        x4 = self.layer4(x3m)\n",
        "        \n",
        "        x5 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x4)\n",
        "        x5 = torch.cat([x5, x3], dim=1)\n",
        "        x5 = self.layer5(x5)\n",
        "        \n",
        "        x6 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x5)\n",
        "        x6 = torch.cat([x6, x2], dim=1)\n",
        "        x6 = self.layer6(x6)\n",
        "        \n",
        "        x7 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x6)\n",
        "        x7 = torch.cat([x7, x1], dim=1)\n",
        "        x7 = self.layer7(x7)\n",
        "        \n",
        "        ret = self.layer8(x7)\n",
        "        return ret\n",
        "        \n",
        "\n",
        "\n",
        "class DiceLoss3(nn.Module):\n",
        "    \"\"\"\n",
        "    class to compute the Dice Loss\n",
        "    \"\"\"\n",
        "    def __init__(self,label):\n",
        "        super().__init__()\n",
        "        self.label = label\n",
        "\n",
        "    def forward(self,outputs):\n",
        "                \n",
        "        # Flatten label and prediction tensors\n",
        "        preds=torch.argmax(outputs,dim=1)\n",
        "\n",
        "        posLabel_mask = self.label>0\n",
        "        negLabel_mask = ~posLabel_mask\n",
        "        posPred_mask = preds>0\n",
        "        negPred_mask = ~posPred_mask\n",
        "\n",
        "        pos_count = posLabel_mask.sum().to(torch.float64)\n",
        "        neg_count = negLabel_mask.sum().to(torch.float64)\n",
        "\n",
        "        trueNeg_count =  (negLabel_mask & negPred_mask).sum().to(torch.float64)\n",
        "        truePos_count =  (posLabel_mask & posPred_mask).sum().to(torch.float64)\n",
        "        falsePos_count = neg_count - trueNeg_count\n",
        "        falseNeg_count = pos_count - truePos_count\n",
        "\n",
        "        N=truePos_count+falsePos_count+falseNeg_count+ 1e-8\n",
        "\n",
        "        #dice loss\n",
        "        dice = (2*truePos_count)/N\n",
        "        loss = 1- dice\n",
        "        \n",
        "\n",
        "        #accuracy \n",
        "        accuracy = (truePos_count + trueNeg_count)/ (pos_count + neg_count + 1e-8)\n",
        "        #precision\n",
        "        precision = truePos_count/ (truePos_count + falsePos_count + 1e-8)\n",
        "        #recall\n",
        "        recall = truePos_count/ (truePos_count + falseNeg_count + 1e-8)\n",
        "\n",
        "        return accuracy, precision, recall, loss"
      ],
      "metadata": {
        "id": "BeFbtI5eLb04"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの定義\n",
        "model = UNet(n_classes=2)\n"
      ],
      "metadata": {
        "id": "Gx64sdORMdbx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n, p in model.named_parameters():\n",
        "    print(n)\n",
        "    #print(p)\n",
        "    print(\"--------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xje_ASNZKK6p",
        "outputId": "8d290ebf-4fdb-4248-a659-43c590757e96"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer1.step.0.weight\n",
            "--------\n",
            "layer1.step.0.bias\n",
            "--------\n",
            "layer1.step.2.weight\n",
            "--------\n",
            "layer1.step.2.bias\n",
            "--------\n",
            "layer2.step.0.weight\n",
            "--------\n",
            "layer2.step.0.bias\n",
            "--------\n",
            "layer2.step.2.weight\n",
            "--------\n",
            "layer2.step.2.bias\n",
            "--------\n",
            "layer3.step.0.weight\n",
            "--------\n",
            "layer3.step.0.bias\n",
            "--------\n",
            "layer3.step.2.weight\n",
            "--------\n",
            "layer3.step.2.bias\n",
            "--------\n",
            "layer4.step.0.weight\n",
            "--------\n",
            "layer4.step.0.bias\n",
            "--------\n",
            "layer4.step.2.weight\n",
            "--------\n",
            "layer4.step.2.bias\n",
            "--------\n",
            "layer5.step.0.weight\n",
            "--------\n",
            "layer5.step.0.bias\n",
            "--------\n",
            "layer5.step.2.weight\n",
            "--------\n",
            "layer5.step.2.bias\n",
            "--------\n",
            "layer6.step.0.weight\n",
            "--------\n",
            "layer6.step.0.bias\n",
            "--------\n",
            "layer6.step.2.weight\n",
            "--------\n",
            "layer6.step.2.bias\n",
            "--------\n",
            "layer7.step.0.weight\n",
            "--------\n",
            "layer7.step.0.bias\n",
            "--------\n",
            "layer7.step.2.weight\n",
            "--------\n",
            "layer7.step.2.bias\n",
            "--------\n",
            "layer8.weight\n",
            "--------\n",
            "layer8.bias\n",
            "--------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "for name, param in model.named_parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "cw-cKxTNKkAz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##logMetrics関数の作成"
      ],
      "metadata": {
        "id": "NKOW9LLlBE9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "METRICS_ACCURACY_NDX=0\n",
        "METRICS_PRECISION_NDX=1\n",
        "METRICS_RECALL_NDX=2\n",
        "METRICS_LOSS_NDX=3\n",
        "\n",
        "METRICS_SIZE = 4\n",
        "\n",
        "def logMetrics(epoch_ndx,phase,metrics_t):\n",
        "  \n",
        "  metrics_dict['phase'].append(phase)\n",
        "  metrics_dict['epoch_ndx'].append(epoch_ndx)\n",
        "  metrics_dict['accuracy'].append(metrics_t[METRICS_ACCURACY_NDX].mean())\n",
        "  metrics_dict['precision'].append(metrics_t[METRICS_PRECISION_NDX].mean())\n",
        "  metrics_dict['recall'].append(metrics_t[METRICS_RECALL_NDX].mean())\n",
        "  metrics_dict['loss'].append(metrics_t[METRICS_LOSS_NDX].mean())\n",
        "\n",
        "  print('{}: Loss: {:.6f} Accuracy: {:.6f} Precision: {:.6f} Recall: {:.6f}'.format(phase,\n",
        "                                                                                    metrics_t[METRICS_ACCURACY_NDX].mean(),\n",
        "                                                                                    metrics_t[METRICS_PRECISION_NDX].mean(),\n",
        "                                                                                    metrics_t[METRICS_RECALL_NDX].mean(),\n",
        "                                                                                    metrics_t[METRICS_LOSS_NDX].mean()))"
      ],
      "metadata": {
        "id": "HfANCZw8xPpe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#学習済みモデルおよび評価指標の保存用の関数の作成"
      ],
      "metadata": {
        "id": "GAEiyXcaPYoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(metrics,epoch_ndx):\n",
        "  save_filename = 'logMetrics2_%s.pickle' % (epoch_ndx)\n",
        "  save_path = os.path.join(metrics_dir,save_filename)\n",
        "  with open(save_path,mode='wb') as f:\n",
        "    pickle.dump(metrics,f)\n",
        "\n",
        "def save_network(network, epoch_ndx):\n",
        "  save_filename = 'net2_%s.pth' % (epoch_ndx)\n",
        "  save_path = os.path.join(network_dir, save_filename)\n",
        "  torch.save(network.cpu().state_dict(), save_path)"
      ],
      "metadata": {
        "id": "2pZXodG7PY6A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train_model関数の作成"
      ],
      "metadata": {
        "id": "TsldyDyEPf-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuJjlMKCTZit",
        "outputId": "3abc6d9f-e5a3-41de-e644-d0b23c0012ba"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_dict = {'epoch_ndx':[],'phase':[],'accuracy':[],'precision':[],'recall':[],'loss':[]}\n",
        "\n",
        "def train_model(model, dataloaders_dict,epoch_start,epoch_end,save_freq):\n",
        "\n",
        "  now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "  print('start time:',now)\n",
        "\n",
        "  t_epoch_start = time.time()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=1e-3,momentum=0.9, weight_decay=5e-4)\n",
        "  num_epochs=epoch_end-epoch_start+1\n",
        "\n",
        "  for epoch_ndx in range(epoch_start,epoch_end+1):\n",
        "    t_epoch_start = time.time()\n",
        "\n",
        "    print('-------------------------------------------------------------------------------------')\n",
        "    print('Epoch {} 【From Epoch {}:To Epoch {}】:Now {}'.format(epoch_ndx,epoch_start,epoch_end,now))\n",
        "    print('-------------------------------------------------------------------------------------')\n",
        "    \n",
        "    model.to(device)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "\n",
        "      if phase == 'train':\n",
        "        model.train()  # モデルを訓練モードに\n",
        "      else:\n",
        "        model.eval()   # モデルを検証モードに\n",
        "\n",
        "      metrics_g = torch.zeros(METRICS_SIZE,len(dataloaders_dict[phase]),device=device,)\n",
        "\n",
        "      # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "      if (epoch_ndx == 0) and (phase == 'train'):\n",
        "        continue\n",
        "\n",
        "      for batch_ndx, batch_tup in enumerate(tqdm(dataloaders_dict[phase])):\n",
        "        input_t, label_t = batch_tup\n",
        "        input_g=input_t.to(device)\n",
        "        label_g=label_t.to(device)\n",
        "        #del input_t,label_t,batch_tup\n",
        "\n",
        "        # optimizerを初期化\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "      # 順伝搬（forward）計算\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "        \n",
        "          outputs = model(input_g)\n",
        "          criterion = DiceLoss3(label_g.long())\n",
        "          accuracy, precision, recall, loss =criterion(outputs)\n",
        "\n",
        "          metrics_g[METRICS_ACCURACY_NDX,batch_ndx] = accuracy.detach()\n",
        "          metrics_g[METRICS_PRECISION_NDX,batch_ndx] = precision.detach()\n",
        "          metrics_g[METRICS_RECALL_NDX,batch_ndx] = recall.detach()\n",
        "          metrics_g[METRICS_LOSS_NDX,batch_ndx] = loss.detach()\n",
        "\n",
        "          # 訓練時はバックプロパゲーション\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "      metrics_t=metrics_g.to('cpu')\n",
        "      logMetrics(epoch_ndx,phase,metrics_t) \n",
        "\n",
        "    if (epoch_ndx % save_freq ==0) & (epoch_ndx>0):\n",
        "      print('saving the model at the end of epoch %d' % (epoch_ndx))\n",
        "      save_network(model,epoch_ndx)\n",
        "      print('saving the logMetrics at the end of epoch %d' % (epoch_ndx))\n",
        "      save_file(metrics_dict,epoch_ndx)      \n",
        "\n",
        "    t_epoch_finish = time.time()\n",
        "    print('Epoch:{} timer:  {:.4f} sec.'.format(epoch_ndx,t_epoch_finish - t_epoch_start)) \n"
      ],
      "metadata": {
        "id": "kGVgkv7BigNu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##①初回学習の実行"
      ],
      "metadata": {
        "id": "oh8X9lYcQh4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### epoch_ndx=0,1,2,3,4,5について学習する\n",
        "###このうち、epoch_ndx=5 については、学習済みモデル及び評価指標を保存する\n",
        "###初回学習のときには、epoch_start=0とする"
      ],
      "metadata": {
        "id": "yeGS5uFLQj2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習・検証を実行する\n",
        "epoch_start=0\n",
        "save_freq=5\n",
        "epoch_end=10\n",
        "\n",
        "train_model(model, dataloaders_dict,epoch_start,epoch_end,save_freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "ybkQQECkQlLB",
        "outputId": "cd12c401-e5d8-4939-8c63-7176b482ae21"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start time: 2022-04-20 13:18:54.222704+09:00\n",
            "-------------------------------------------------------------------------------------\n",
            "Epoch 0 【From Epoch 0:To Epoch 10】:Now 2022-04-20 13:18:54.222704+09:00\n",
            "-------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/228 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "100%|██████████| 228/228 [00:22<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val: Loss: 0.993726 Accuracy: 0.000000 Precision: 0.000000 Recall: 1.000000\n",
            "Epoch:0 timer:  26.1374 sec.\n",
            "-------------------------------------------------------------------------------------\n",
            "Epoch 1 【From Epoch 0:To Epoch 10】:Now 2022-04-20 13:18:54.222704+09:00\n",
            "-------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/228 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-48be143b4ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepoch_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_end\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-7b5ef24c6722>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders_dict, epoch_start, epoch_end, save_freq)\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;31m# 訓練時はバックプロパゲーション\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp5W9VX-lr5n"
      },
      "source": [
        "#END"
      ]
    }
  ]
}